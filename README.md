# Thermal_image_recognition
The sign language digits based on hand gestures have been utilized in various applications such as human-computer interaction, robotics, health and medical systems, health assistive technologies, automotive user interfaces, crisis management and disaster relief, entertainment, and contactless communication in smart devices. The color and depth cameras are commonly deployed for hand gesture recognition, but the robust classification of hand gestures under varying illumination is still a challenging task. This work presents the design and deployment of a complete end-to-end edge computing system that can accurately provide the classification of hand gestures captured from thermal images. A thermal dataset of 3200 images was created with each sign language digit having 320 thermal images. In this repository you will find the deep learning model used for claasification of thermal images.The designed model achieves an accuracy of 99.52\% on the test data set with an added advantage of accuracy being invariable to background lighting conditions as it is based on thermal imaging.

# Dataset

# Model Architecture

# Results

# How to run
All the code necessary to create and train the model is presented in the main.py file. The trained model can be accesed here https://drive.google.com/file/d/1-0YoSzpZZXgZQhd4F3dwLSlmaQ2ol2_J/view?usp=sharing . 
